{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pdf parser\n",
    "import fitz\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-hmErCKUzvvlgDRNZC6cRT3BlbkFJ5tRAaB2P5Nr8WQiKnyms\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_KEY2\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elementClass(BaseModel):\n",
    "    element_id:str = Field(description=\"the number of the given element.\")\n",
    "    description:str = Field(description=\"The text describing the element.\")\n",
    "    name:str = Field(description=\"A short text representing the element.\")\n",
    "    keywords:list[str] = Field(description= \"some keywords of the element which can be usefull for filtering purposes.\")\n",
    "    value: float = Field(description=\"the value of the element. should be between 0 and 1.0.\")\n",
    "    deifficulty:str = Field(description=\"The difficulty of the element. should be a letter between A-J or SA or TA.\")\n",
    "\n",
    "    # setup validator\n",
    "    @validator(\"value\")\n",
    "    def check_value(cls, value):\n",
    "        if value < 0 or value > 1.0:\n",
    "            raise ValueError(\"value should be between 0 and 1.0\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=elementClass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"extract the elements from the pdf page. multiple elements can be extracted from the page.\"\n",
    "prompt = PromptTemplate(template=template, input_variables = [\"context\"], partial_variables={\"format_instructions\": parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf():\n",
    "    loader = fitz.open(\"files/Women/en_2022-2024 WAG COP.pdf\")\n",
    "    # pages = loader.load()\n",
    "    return loader \n",
    "loader = load_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 ʊ MO8N7S \n",
      " \n",
      "UB – Group 1 - 2 \n",
      "A \n",
      "B \n",
      "C \n",
      "D \n",
      "E \n",
      "F/G \n",
      "1.103  \n",
      "Glide on LB (or swing fwd on \n",
      "HB) and stoop through to rear \n",
      "support (back kip); or straddle \n",
      "cut bwd to hang on same bar \n",
      " \n",
      " \n",
      "1.203  \n",
      "Reverse kip from: – glide fwd on \n",
      "LB – swing fwd on HB – stoop \n",
      "through to kip hang, back kip \n",
      "swing, seat (pike) circle bwd to \n",
      "rear support \n",
      " \n",
      "1.303 \n",
      " \n",
      "1.403 \n",
      "1.503 \n",
      "1.603 \n",
      "1.104  \n",
      "Jump to hang on HB – also with \n",
      "reverse grip – kip to support \n",
      " \n",
      "1.204  \n",
      "Facing HB – Jump with ½ turn \n",
      "(180°) – kip to support on HB \n",
      " \n",
      " \n",
      "Free jump with ½ turn (180°) over \n",
      "LB to hang on HB \n",
      " \n",
      "1.304  \n",
      "Jump with ½ turn (180°) over \n",
      "LB – kip to support on HB \n",
      " \n",
      " \n",
      "1.404  \n",
      "1.504 \n",
      "1.604 \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_page = loader.load_page(73).get_text()\n",
    "print(pdf_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chain.invoke({\"context\":pdf_page})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Loes\\miniconda3\\envs\\routineBuilder\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Loes\\miniconda3\\envs\\routineBuilder\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Loes\\miniconda3\\envs\\routineBuilder\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Loes\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.403 \n",
      "1.503 \n",
      "1.603 \n",
      "1.104  \n",
      "Jump to hang on HB – also with \n",
      "reverse grip – kip to support \n"
     ]
    }
   ],
   "source": [
    "print(pdf_page.split(\"\\n \\n\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(\"get this text:\"+ pdf_page.split(\"\\n \\n\")[4], return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=100, temperature=0.7, do_sample=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get this text:1.403 \n",
      "1.503 \n",
      "1.603 \n",
      "1.104  \n",
      "Jump to hang on HB – also with \n",
      "reverse grip – kip to support \n",
      "\n",
      "1.105 \n",
      "\n",
      "1.106 \n",
      "\n",
      "1.107 \n",
      "\n",
      "1.108 \n",
      "\n",
      "1.109 \n",
      "\n",
      "1.110 \n",
      "\n",
      "1.111 \n",
      "\n",
      "1.112 \n",
      "\n",
      "1.113 \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 50, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "result = summarizer(pdf_page.split(\"\\n \\n\")[4], max_length=50, min_length=25, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_text': ' Jumped to hang on HB – also with  reverse grip – kip to support . 1.403  \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa01.503  \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0.603  \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0: \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\\xa0receive\\xa0reversal grip .'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "routineBuilder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
